import base64
import glob
import io
import os

from PIL import Image

from utils.logging_config import get_logger

logger = get_logger(__name__)
import concurrent.futures  # æ·»åŠ å° concurrent.futures çš„å°å…¥
import hashlib
import re
from typing import Any, Dict, List, Optional, Tuple, Union

from langchain_core.messages import HumanMessage
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai.chat_models import ChatOpenAI

from utils.LLM_Tool import gpt_4o, gpt_4o_for_summary, text_embedding_3_large


# ç‚ºå–®å€‹å¹»ç‡ˆç‰‡ç”Ÿæˆæ‘˜è¦çš„è¼”åŠ©å‡½æ•¸
def _process_single_slide(args):
    """
    ç‚ºå–®å€‹ PPTX å¹»ç‡ˆç‰‡ç”Ÿæˆæ‘˜è¦çš„è¼”åŠ©å‡½æ•¸
    args: åŒ…å« (llm, slide_num, img_path, file_name) çš„å…ƒçµ„
    å›å‚³ï¼š(summary, slide_identifier, slide_num) çš„å…ƒçµ„
    """
    llm, slide_num, img_path, file_name = args

    try:
        # å°‡åœ–ç‰‡è½‰æ›ç‚º base64
        img_base64 = encode_image(img_path)

        # å‰µå»ºå¹»ç‡ˆç‰‡æ¨™è­˜ç¬¦
        slide_identifier = f"{os.path.splitext(file_name)[0]}_slide_{slide_num}"

        # æº–å‚™æç¤º
        system_prompt = """æ‚¨æ˜¯ä¸€åè©³ç´°çš„ç°¡å ±åˆ†æå°ˆå®¶ã€‚æ‚¨çš„ä»»å‹™æ˜¯å°PowerPointå¹»ç‡ˆç‰‡é€²è¡Œå…¨é¢åˆ†æå’Œæ‘˜è¦ã€‚
        è«‹æä¾›è©³ç´°çš„æ‘˜è¦ï¼ŒåŒ…å«ä»¥ä¸‹å…§å®¹ï¼š
        1. è©²å¹»ç‡ˆç‰‡çš„ä¸»è¦å…§å®¹å’Œä¸»é¡Œ
        2. å¹»ç‡ˆç‰‡ä¸Šæ‰€æœ‰åœ–ç‰‡çš„è©³ç´°æè¿°ï¼ˆå¦‚æœæœ‰ï¼‰
        3. å¹»ç‡ˆç‰‡ä¸Šæ‰€æœ‰è¡¨æ ¼çš„å…§å®¹å’Œçµæ§‹ï¼ˆå¦‚æœæœ‰ï¼‰
        4. è©²å¹»ç‡ˆç‰‡çš„é—œéµæ¦‚å¿µå’Œè¦é»
        
        è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œä¸¦æä¾›ä¸€å€‹çµæ§‹æ¸…æ™°çš„è©³ç´°æ‘˜è¦ã€‚"""

        user_content = [
            {
                "type": "image_url",
                "image_url": {"url": f"data:image/jpeg;base64,{img_base64}"},
            },
            {
                "type": "text",
                "text": f"é€™æ˜¯ {file_name} çš„ç¬¬ {slide_num} å¼µå¹»ç‡ˆç‰‡ã€‚è«‹å°é€™å¼µå¹»ç‡ˆç‰‡é€²è¡Œè©³ç´°åˆ†æå’Œæ‘˜è¦ï¼ŒåŒ…å«å¹»ç‡ˆç‰‡ä¸»è¦å…§å®¹ã€åœ–ç‰‡æè¿°ã€è¡¨æ ¼å…§å®¹å’Œé—œéµæ¦‚å¿µã€‚",
            },
        ]

        # å‰µå»ºæ¶ˆæ¯å°è±¡
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_content},
        ]

        # å‘¼å« GPT-4o ç”Ÿæˆæ‘˜è¦
        response = llm.invoke(messages)
        summary = response.content

        logger.info(f"âœ… æˆåŠŸç‚º {file_name} ç¬¬ {slide_num} å¼µå¹»ç‡ˆç‰‡ç”Ÿæˆæ‘˜è¦")
        return summary, slide_identifier, slide_num
    except Exception as e:
        logger.error(f"âŒ è™•ç† {file_name} ç¬¬ {slide_num} å¼µå¹»ç‡ˆç‰‡æ™‚å‡ºéŒ¯: {e}")
        return None, None, slide_num


# æ–°å¢çš„ PPTX å¹»ç‡ˆç‰‡æ‘˜è¦ç”Ÿæˆå‡½æ•¸
def generate_pptx_slide_summaries(
    file_path: str,
    file_name: str,
    slide_image_paths: List[Tuple[int, str]],
    max_workers: int = 4,
) -> Tuple[List[str], List[str]]:
    """
    ç‚º PPTX æ¯ä¸€å¼µå¹»ç‡ˆç‰‡ç”Ÿæˆè©³ç´°æ‘˜è¦
    file_path: PPTX æª”æ¡ˆæ‰€åœ¨è³‡æ–™å¤¾è·¯å¾‘
    file_name: PPTX æª”æ¡ˆåç¨±
    slide_image_paths: åŒ…å«(å¹»ç‡ˆç‰‡ç·¨è™Ÿ, åœ–ç‰‡è·¯å¾‘)çš„åˆ—è¡¨
    max_workers: æœ€å¤§ä¸¦è¡Œå·¥ä½œç·šç¨‹æ•¸
    å›å‚³ï¼šæ‘˜è¦åˆ—è¡¨å’Œå°æ‡‰çš„å¹»ç‡ˆç‰‡æ¨™è­˜ç¬¦åˆ—è¡¨
    """
    if not slide_image_paths:
        logger.error(f"âŒ æœªæ‰¾åˆ° {file_name} çš„å¹»ç‡ˆç‰‡åœ–ç‰‡ï¼Œç„¡æ³•ç”Ÿæˆæ‘˜è¦")
        return [], []

    # åˆå§‹åŒ–çµæœåˆ—è¡¨
    slide_summaries = []
    slide_identifiers = []  # æ ¼å¼: "filename_slide_N"

    # åˆå§‹åŒ– GPT-4o æ¨¡å‹ (åªåˆå§‹åŒ–ä¸€æ¬¡)
    llm = gpt_4o_for_summary()

    # æº–å‚™å·¥ä½œåƒæ•¸
    tasks = [
        (llm, slide_num, img_path, file_name)
        for slide_num, img_path in slide_image_paths
    ]

    # è¨­å®šæœ€å¤§å·¥ä½œç·šç¨‹æ•¸ï¼Œä¸è¶…éå¹»ç‡ˆç‰‡æ•¸é‡
    actual_max_workers = min(max_workers, len(slide_image_paths))
    logger.info(
        f"ğŸš€ é–‹å§‹ä¸¦è¡Œè™•ç† {file_name} çš„ {len(slide_image_paths)} å¼µå¹»ç‡ˆç‰‡ï¼Œä½¿ç”¨ {actual_max_workers} å€‹ä¸¦è¡Œå·¥ä½œç·šç¨‹"
    )

    # ä½¿ç”¨ç·šç¨‹æ± ä¸¦è¡Œè™•ç†
    processed_slides = 0
    failed_slides = 0
    with concurrent.futures.ThreadPoolExecutor(
        max_workers=actual_max_workers
    ) as executor:
        # æäº¤æ‰€æœ‰ä»»å‹™
        future_to_slide = {
            executor.submit(_process_single_slide, task): task[1] for task in tasks
        }

        # æŒ‰å®Œæˆé †åºè™•ç†çµæœ
        for future in concurrent.futures.as_completed(future_to_slide):
            slide_num = future_to_slide[future]
            try:
                summary, slide_identifier, _ = future.result()
                if summary and slide_identifier:
                    slide_summaries.append(summary)
                    slide_identifiers.append(slide_identifier)
                    processed_slides += 1
                else:
                    failed_slides += 1
            except Exception as e:
                logger.error(
                    f"âŒ ç²å– {file_name} ç¬¬ {slide_num} å¼µå¹»ç‡ˆç‰‡çš„æ‘˜è¦çµæœæ™‚å‡ºéŒ¯: {e}"
                )
                failed_slides += 1

    logger.info(
        f"ğŸ“Š ä¸¦è¡Œè™•ç†å®Œæˆï¼šæˆåŠŸç‚º {processed_slides}/{len(slide_image_paths)} å¼µå¹»ç‡ˆç‰‡ç”Ÿæˆäº†æ‘˜è¦ï¼Œå¤±æ•— {failed_slides} å¼µ"
    )

    # ç¢ºä¿çµæœæŒ‰å¹»ç‡ˆç‰‡é †åºæ’åº
    # ç”±æ–¼ä¸¦è¡Œè™•ç†å¯èƒ½å°è‡´çµæœé †åºæ··äº‚ï¼Œé€™è£¡é‡æ–°æŒ‰å¹»ç‡ˆç‰‡ç·¨è™Ÿæ’åº
    if len(slide_summaries) > 0:
        # å¾slide_identifiersä¸­æå–å¹»ç‡ˆç‰‡ç·¨è™Ÿ
        slide_numbers = [int(sid.split("_")[-1]) for sid in slide_identifiers]
        # æŒ‰å¹»ç‡ˆç‰‡ç·¨è™Ÿæ’åº
        sorted_results = sorted(
            zip(slide_summaries, slide_identifiers, slide_numbers), key=lambda x: x[2]
        )
        # è§£åŒ…æ’åºå¾Œçš„çµæœ
        slide_summaries = [result[0] for result in sorted_results]
        slide_identifiers = [result[1] for result in sorted_results]

    return slide_summaries, slide_identifiers


# ç‚ºå–®å€‹é é¢ç”Ÿæˆæ‘˜è¦çš„è¼”åŠ©å‡½æ•¸
def _process_single_page(args):
    """
    ç‚ºå–®å€‹ PDF é é¢ç”Ÿæˆæ‘˜è¦çš„è¼”åŠ©å‡½æ•¸
    args: åŒ…å« (llm, page_num, img_path, file_name) çš„å…ƒçµ„
    å›å‚³ï¼š(summary, page_identifier, page_num) çš„å…ƒçµ„
    """
    llm, page_num, img_path, file_name = args

    try:
        # å°‡åœ–ç‰‡è½‰æ›ç‚º base64
        img_base64 = encode_image(img_path)

        # å‰µå»ºé é¢æ¨™è­˜ç¬¦
        page_identifier = f"{os.path.splitext(file_name)[0]}_page_{page_num}"

        # æº–å‚™æç¤º
        system_prompt = """æ‚¨æ˜¯ä¸€åè©³ç´°çš„æ–‡ä»¶åˆ†æå°ˆå®¶ã€‚æ‚¨çš„ä»»å‹™æ˜¯å°PDFçš„æ¯ä¸€é é€²è¡Œå…¨é¢åˆ†æå’Œæ‘˜è¦ã€‚
        è«‹æä¾›è©³ç´°çš„æ‘˜è¦ï¼ŒåŒ…å«ä»¥ä¸‹å…§å®¹ï¼š
        1. è©²é é¢çš„ä¸»è¦å…§å®¹å’Œä¸»é¡Œ
        2. é é¢ä¸Šæ‰€æœ‰åœ–ç‰‡çš„è©³ç´°æè¿°ï¼ˆå¦‚æœæœ‰ï¼‰
        3. é é¢ä¸Šæ‰€æœ‰è¡¨æ ¼çš„å…§å®¹å’Œçµæ§‹ï¼ˆå¦‚æœæœ‰ï¼‰
        4. è©²é é¢çš„é—œéµæ¦‚å¿µå’Œè¦é»
        
        è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œä¸¦æä¾›ä¸€å€‹çµæ§‹æ¸…æ™°çš„è©³ç´°æ‘˜è¦ã€‚"""

        user_content = [
            {
                "type": "image_url",
                "image_url": {"url": f"data:image/jpeg;base64,{img_base64}"},
            },
            {
                "type": "text",
                "text": f"é€™æ˜¯ {file_name} çš„ç¬¬ {page_num} é ã€‚è«‹å°é€™ä¸€é é€²è¡Œè©³ç´°åˆ†æå’Œæ‘˜è¦ï¼ŒåŒ…å«é é¢ä¸»è¦å…§å®¹ã€åœ–ç‰‡æè¿°ã€è¡¨æ ¼å…§å®¹å’Œé—œéµæ¦‚å¿µã€‚",
            },
        ]

        # å‰µå»ºæ¶ˆæ¯å°è±¡
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_content},
        ]

        # å‘¼å« GPT-4o ç”Ÿæˆæ‘˜è¦
        response = llm.invoke(messages)
        summary = response.content

        logger.info(f"âœ… æˆåŠŸç‚º {file_name} ç¬¬ {page_num} é ç”Ÿæˆæ‘˜è¦")
        return summary, page_identifier, page_num
    except Exception as e:
        logger.error(f"âŒ è™•ç† {file_name} ç¬¬ {page_num} é æ™‚å‡ºéŒ¯: {e}")
        return None, None, page_num


# æ–°å¢çš„ PDF é é¢æ‘˜è¦ç”Ÿæˆå‡½æ•¸ (ä¸¦è¡Œç‰ˆæœ¬)
def generate_pdf_page_summaries(
    file_path: str,
    file_name: str,
    page_image_paths: List[Tuple[int, str]],
    max_workers: int = 6,
) -> Tuple[List[str], List[str]]:
    """
    ç‚º PDF æ¯ä¸€é ç”Ÿæˆè©³ç´°æ‘˜è¦ (ä¸¦è¡Œè™•ç†ç‰ˆæœ¬)
    file_path: PDF æª”æ¡ˆæ‰€åœ¨è³‡æ–™å¤¾è·¯å¾‘
    file_name: PDF æª”æ¡ˆåç¨±
    page_image_paths: åŒ…å«(é ç¢¼, åœ–ç‰‡è·¯å¾‘)çš„åˆ—è¡¨
    max_workers: æœ€å¤§ä¸¦è¡Œå·¥ä½œç·šç¨‹æ•¸
    å›å‚³ï¼šæ‘˜è¦åˆ—è¡¨å’Œå°æ‡‰çš„é é¢æ¨™è­˜ç¬¦åˆ—è¡¨
    """
    if not page_image_paths:
        logger.error(f"âŒ æœªæ‰¾åˆ° {file_name} çš„é é¢åœ–ç‰‡ï¼Œç„¡æ³•ç”Ÿæˆæ‘˜è¦")
        return [], []

    # åˆå§‹åŒ–çµæœåˆ—è¡¨
    page_summaries = []
    page_identifiers = []  # æ ¼å¼: "filename_page_N"

    # åˆå§‹åŒ– GPT-4o æ¨¡å‹ (åªåˆå§‹åŒ–ä¸€æ¬¡)
    llm = gpt_4o_for_summary()

    # æº–å‚™å·¥ä½œåƒæ•¸
    tasks = [
        (llm, page_num, img_path, file_name) for page_num, img_path in page_image_paths
    ]

    # è¨­å®šæœ€å¤§å·¥ä½œç·šç¨‹æ•¸ï¼Œä¸è¶…éé é¢æ•¸é‡
    actual_max_workers = min(max_workers, len(page_image_paths))
    logger.info(
        f"ğŸš€ é–‹å§‹ä¸¦è¡Œè™•ç† {file_name} çš„ {len(page_image_paths)} é ï¼Œä½¿ç”¨ {actual_max_workers} å€‹ä¸¦è¡Œå·¥ä½œç·šç¨‹"
    )

    # ä½¿ç”¨ç·šç¨‹æ± ä¸¦è¡Œè™•ç†
    processed_pages = 0
    failed_pages = 0
    with concurrent.futures.ThreadPoolExecutor(
        max_workers=actual_max_workers
    ) as executor:
        # æäº¤æ‰€æœ‰ä»»å‹™
        future_to_page = {
            executor.submit(_process_single_page, task): task[1] for task in tasks
        }

        # æŒ‰å®Œæˆé †åºè™•ç†çµæœ
        for future in concurrent.futures.as_completed(future_to_page):
            page_num = future_to_page[future]
            try:
                summary, page_identifier, _ = future.result()
                if summary and page_identifier:
                    page_summaries.append(summary)
                    page_identifiers.append(page_identifier)
                    processed_pages += 1
                else:
                    failed_pages += 1
            except Exception as e:
                logger.error(
                    f"âŒ ç²å– {file_name} ç¬¬ {page_num} é çš„æ‘˜è¦çµæœæ™‚å‡ºéŒ¯: {e}"
                )
                failed_pages += 1

    logger.info(
        f"ğŸ“Š ä¸¦è¡Œè™•ç†å®Œæˆï¼šæˆåŠŸç‚º {processed_pages}/{len(page_image_paths)} é ç”Ÿæˆäº†æ‘˜è¦ï¼Œå¤±æ•— {failed_pages} é "
    )

    # ç¢ºä¿çµæœæŒ‰é ç¢¼é †åºæ’åº
    # ç”±æ–¼ä¸¦è¡Œè™•ç†å¯èƒ½å°è‡´çµæœé †åºæ··äº‚ï¼Œé€™è£¡é‡æ–°æŒ‰é ç¢¼æ’åº
    if len(page_summaries) > 0:
        # å¾page_identifiersä¸­æå–é ç¢¼
        page_numbers = [int(pid.split("_")[-1]) for pid in page_identifiers]
        # æŒ‰é ç¢¼æ’åº
        sorted_results = sorted(
            zip(page_summaries, page_identifiers, page_numbers), key=lambda x: x[2]
        )
        # è§£åŒ…æ’åºå¾Œçš„çµæœ
        page_summaries = [result[0] for result in sorted_results]
        page_identifiers = [result[1] for result in sorted_results]

    return page_summaries, page_identifiers


def generate_text_summaries(texts_4k_token, table_strings, summarize_texts=True):
    """
    ç‚ºæ–‡å­—å’Œè¡¨æ ¼ç”Ÿæˆæ‘˜è¦
    texts_4k_token: æ–‡å­—å€å¡Šåˆ—è¡¨
    table_strings: è¡¨æ ¼å­—ä¸²åˆ—è¡¨
    summarize_texts: æ˜¯å¦ç‚ºæ–‡å­—ç”Ÿæˆæ‘˜è¦
    å›å‚³ï¼šæ–‡å­—æ‘˜è¦åˆ—è¡¨ã€è¡¨æ ¼æ‘˜è¦åˆ—è¡¨
    """
    # æç¤º
    prompt_text = """æ‚¨æ˜¯ä¸€ååŠ©æ‰‹ï¼Œè² è²¬æ‘˜è¦è¡¨æ ¼å’Œæ–‡æœ¬ã€‚ \
    é€™äº›æ‘˜è¦å°‡è¢«ä½œç‚ºembeddingä¸¦ç”¨æ–¼æª¢ç´¢åŸå§‹æ–‡æœ¬æˆ–è¡¨æ ¼å…ƒç´ ã€‚ \
    è«‹æä¾›é‡å°æª¢ç´¢å„ªåŒ–çš„è©³ç´°æ‘˜è¦ã€‚è¡¨æ ¼æˆ–æ–‡æœ¬ï¼š{element} """
    prompt = ChatPromptTemplate.from_template(prompt_text)

    # æ–‡æœ¬æ‘˜è¦éˆ
    model = gpt_4o_for_summary()
    summarize_chain = {"element": lambda x: x} | prompt | model | StrOutputParser()

    # åˆå§‹åŒ–æ‘˜è¦åˆ—è¡¨
    text_summaries = []
    table_summaries = []

    # å¦‚æœæä¾›æ–‡æœ¬ä¸”éœ€è¦æ‘˜è¦ï¼Œå‰‡æ‡‰ç”¨æ–¼æ–‡æœ¬
    if texts_4k_token and summarize_texts:
        text_summaries = summarize_chain.batch(texts_4k_token, {"max_concurrency": 4})
    elif texts_4k_token:
        text_summaries = texts_4k_token

    # å¦‚æœæä¾›è¡¨æ ¼ï¼Œå‰‡æ‡‰ç”¨æ–¼è¡¨æ ¼
    if table_strings:
        table_summaries = summarize_chain.batch(table_strings, {"max_concurrency": 4})

    return text_summaries, table_summaries


def encode_image(image_path):
    """å°‡åœ–ç‰‡ç·¨ç¢¼ç‚º base64 å­—ä¸²"""
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")


def is_meaningful_image(image_path, min_width=100, min_height=100, min_file_size_kb=10):
    """
    åˆ¤æ–·åœ–ç‰‡æ˜¯å¦æœ‰æ„ç¾©
    image_path: åœ–ç‰‡è·¯å¾‘
    min_width: æœ€å°å¯¬åº¦ (åƒç´ )
    min_height: æœ€å°é«˜åº¦ (åƒç´ )
    min_file_size_kb: æœ€å°æ–‡ä»¶å¤§å° (KB)
    å›å‚³ï¼šåœ–ç‰‡æ˜¯å¦æœ‰æ„ç¾©
    """
    try:
        # æª¢æŸ¥æ–‡ä»¶å¤§å°
        file_size_kb = os.path.getsize(image_path) / 1024
        if file_size_kb < min_file_size_kb:
            return False

        # æª¢æŸ¥åœ–ç‰‡å°ºå¯¸
        with Image.open(image_path) as img:
            width, height = img.size
            if width < min_width or height < min_height:
                return False

            # æª¢æŸ¥åœ–ç‰‡æ˜¯å¦ç‚ºç©ºç™½æˆ–å–®è‰²
            if img.mode == "RGB":
                # æ¡æ¨£æª¢æŸ¥åœ–ç‰‡è¤‡é›œåº¦
                colors = img.getcolors(maxcolors=256)
                # å¦‚æœé¡è‰²ç¨®é¡éå¸¸å°‘ï¼Œå¯èƒ½æ˜¯è£é£¾åœ–ç‰‡
                if colors is not None and len(colors) < 5:
                    return False

        return True
    except Exception as e:
        logger.info(f"æª¢æŸ¥åœ–ç‰‡æ™‚å‡ºéŒ¯ {image_path}: {e}")
        return False


def get_image_hash(image_path):
    """
    ç²å–åœ–ç‰‡çš„å“ˆå¸Œå€¼ï¼Œç”¨æ–¼å»é‡
    image_path: åœ–ç‰‡è·¯å¾‘
    å›å‚³ï¼šåœ–ç‰‡å“ˆå¸Œå€¼
    """
    try:
        with Image.open(image_path) as img:
            # èª¿æ•´å¤§å°ä»¥åŠ å¿«å“ˆå¸Œè¨ˆç®—
            img = img.resize((64, 64), Image.LANCZOS)
            # è½‰ç‚ºç°åº¦
            if img.mode != "L":
                img = img.convert("L")
            # è¨ˆç®—å“ˆå¸Œ
            pixels = list(img.getdata())
            avg = sum(pixels) / len(pixels)
            bits = "".join("1" if pixel > avg else "0" for pixel in pixels)
            hexadecimal = hex(int(bits, 2))[2:][:16].zfill(16)
            return hexadecimal
    except Exception as e:
        logger.info(f"è¨ˆç®—åœ–ç‰‡å“ˆå¸Œæ™‚å‡ºéŒ¯ {image_path}: {e}")
        return None


def extract_image_paths(figures_dir: str, filter_images=True) -> list:
    """
    å¾åœ–ç‰‡ç›®éŒ„æå–åœ–ç‰‡è·¯å¾‘ï¼Œä¸¦éæ¿¾ç„¡æ„ç¾©çš„åœ–ç‰‡
    figures_dir: åœ–ç‰‡ç›®éŒ„è·¯å¾‘
    filter_images: æ˜¯å¦éæ¿¾ç„¡æ„ç¾©çš„åœ–ç‰‡
    å›å‚³ï¼šåœ–ç‰‡è·¯å¾‘åˆ—è¡¨
    """
    DATABASE_DIR = "./database"
    image_paths = []

    # æª¢æŸ¥ figures_dir æ˜¯å¦å­˜åœ¨
    if not os.path.exists(figures_dir):
        logger.warning(f"âš ï¸ åœ–ç‰‡ç›®éŒ„ä¸å­˜åœ¨: {figures_dir}")
        return []

    # ç²å–æ‰€æœ‰å­ç›®éŒ„
    subdirs = [
        d
        for d in os.listdir(figures_dir)
        if os.path.isdir(os.path.join(figures_dir, d))
    ]

    # è™•ç†æ¯å€‹å­ç›®éŒ„ä¸­çš„åœ–ç‰‡
    for subdir in subdirs:
        subdir_path = os.path.join(figures_dir, subdir)

        # ç²å–å­ç›®éŒ„ä¸­çš„æ‰€æœ‰åœ–ç‰‡
        image_extensions = ["*.jpg", "*.jpeg", "*.png", "*.gif", "*.bmp"]
        for ext in image_extensions:
            pattern = os.path.join(subdir_path, ext)
            image_paths.extend(glob.glob(pattern))

    # å¦‚æœæ²’æœ‰æ‰¾åˆ°åœ–ç‰‡ï¼Œè¨˜éŒ„è­¦å‘Š
    if not image_paths:
        logger.warning(f"âš ï¸ åœ¨ {figures_dir} åŠå…¶å­ç›®éŒ„ä¸­æœªæ‰¾åˆ°ä»»ä½•åœ–ç‰‡")
        return []

    # éæ¿¾ç„¡æ„ç¾©çš„åœ–ç‰‡
    if filter_images:
        logger.info(f"ğŸ” é–‹å§‹éæ¿¾åœ–ç‰‡ï¼ŒåŸå§‹åœ–ç‰‡æ•¸é‡: {len(image_paths)}")

        filtered_paths = []
        image_hashes = set()  # ç”¨æ–¼å­˜å„²å·²è™•ç†éçš„åœ–ç‰‡å“ˆå¸Œå€¼

        for img_path in image_paths:
            # æª¢æŸ¥åœ–ç‰‡æ˜¯å¦æœ‰æ„ç¾©
            if is_meaningful_image(img_path):
                # è¨ˆç®—åœ–ç‰‡å“ˆå¸Œå€¼ç”¨æ–¼å»é‡
                img_hash = get_image_hash(img_path)
                if img_hash and img_hash not in image_hashes:
                    image_hashes.add(img_hash)
                    filtered_paths.append(img_path)

        logger.info(
            f"ğŸ” éæ¿¾å®Œæˆï¼Œéæ¿¾å¾Œåœ–ç‰‡æ•¸é‡: {len(filtered_paths)}/{len(image_paths)}"
        )
        return filtered_paths

    return image_paths


def generate_img_summaries(
    figures_dir: str, filter_images=True
) -> Tuple[List[str], List[str]]:
    """
    ç‚ºåœ–ç‰‡ç”Ÿæˆæ‘˜è¦
    figures_dir: åœ–ç‰‡ç›®éŒ„è·¯å¾‘
    filter_images: æ˜¯å¦éæ¿¾ç„¡æ„ç¾©çš„åœ–ç‰‡
    å›å‚³ï¼šæ‘˜è¦åˆ—è¡¨å’Œå°æ‡‰çš„åœ–ç‰‡æ–‡ä»¶ååˆ—è¡¨
    """
    # ç²å–æ‰€æœ‰åœ–ç‰‡è·¯å¾‘ï¼Œä¸¦éæ¿¾ç„¡æ„ç¾©çš„åœ–ç‰‡
    image_paths = extract_image_paths(figures_dir, filter_images=filter_images)
    if not image_paths:
        logger.error("âŒ æ²’æœ‰æ‰¾åˆ°ä»»ä½•æœ‰æ„ç¾©çš„åœ–ç‰‡ï¼Œç„¡æ³•ç”Ÿæˆæ‘˜è¦")
        return [], []

    img_summaries = []
    img_filenames = []  # ç”¨æ–¼å­˜å„²ç›¸å°è·¯å¾‘

    # ç‚ºæ¯å¼µåœ–ç‰‡ç”Ÿæˆæ‘˜è¦
    for img_path in image_paths:
        # è½‰æ›ç‚ºç›¸å°è·¯å¾‘ (å¾ database/figures/ é–‹å§‹)
        img_relative_path = os.path.relpath(img_path, os.path.dirname(figures_dir))

        # å°‡åœ–ç‰‡è½‰æ›ç‚º base64
        try:
            img_base64 = encode_image(img_path)

            # åˆå§‹åŒ– GPT-4o æ¨¡å‹
            llm = gpt_4o_for_summary()

            # æº–å‚™æ¶ˆæ¯
            system_message = {
                "role": "system",
                "content": "ç”¨ç¹é«”ä¸­æ–‡å›ç­”å’Œä½¿ç”¨ç›´è¦ºç°¡æ˜çš„æ–¹å¼èªªæ˜åœ–ç‰‡å…§å®¹ï¼šè«‹æè¿°é€™å¼µåœ–ç‰‡ä¸­æœ‰ä»€éº¼ï¼Œç›¡é‡ç´°ç¯€åˆ°ä½ã€‚å›ç­”è¦å…¨éƒ¨éƒ½åªæœ‰ä¸€æ®µè©±ï¼Œä¸è¦ä½¿ç”¨æ¢åˆ—å¼æˆ–æ˜¯é …ç›®ç¬¦è™Ÿã€‚",
            }
            user_content = [
                {
                    "type": "image_url",
                    "image_url": {"url": f"data:image/jpeg;base64,{img_base64}"},
                },
                {
                    "type": "text",
                    "text": "ç°¡æ˜æ‰¼è¦åœ°æè¿°é€™å¼µåœ–ç‰‡é¡¯ç¤ºäº†ä»€éº¼å…§å®¹ã€‚å›è¦†åªéœ€è¦ä¸€æ®µæ–‡å­—ï¼Œä¸è¦ä½¿ç”¨æ¢åˆ—å¼ã€‚",
                },
            ]

            # å‰µå»ºæ¶ˆæ¯å°è±¡
            messages = [HumanMessage(content=user_content)]

            # å‘¼å« GPT-4o ç”Ÿæˆæ‘˜è¦
            response = llm.invoke(messages)
            summary = response.content

            # æ·»åŠ æ‘˜è¦å’Œæ–‡ä»¶ååˆ°åˆ—è¡¨
            img_summaries.append(summary)
            img_filenames.append(img_relative_path)

            logger.info(f"âœ… æˆåŠŸç‚ºåœ–ç‰‡ {img_relative_path} ç”Ÿæˆæ‘˜è¦")
        except Exception as e:
            logger.error(f"âŒ è™•ç†åœ–ç‰‡ {img_path} æ™‚å‡ºéŒ¯: {e}")

    logger.info(f"ğŸ“Š å…±ç‚º {len(img_summaries)}/{len(image_paths)} å¼µåœ–ç‰‡ç”Ÿæˆäº†æ‘˜è¦")
    return img_summaries, img_filenames


if __name__ == "__main__":
    logger.info(
        "This module is part of the processing pipeline; invoke it via app.py or main.py."
    )
